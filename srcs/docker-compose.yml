services:
  pytorch:
    container_name: LiteHRNet
    build:
      context: ./models/Lite-HRNet
      dockerfile: Dockerfile
      shm_size: '6gb'
    stop_signal: SIGKILL
    tty: true
    restart: unless-stopped
    shm_size: '6gb'
    ports:
      - "8080:8080"
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              device_ids: ['0']
              capabilities: [gpu]
    volumes:
      - ./models/Lite-HRNet:/workspace/Lite-HRNet
